{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVruFNRjODs9"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrk-ZyzEUcrG",
        "outputId": "9d4afe17-2415-47eb-ee7f-7b3c3d5337f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 19 15:28:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xu8offvO2Uj"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  \n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHe297hDPBgd"
      },
      "outputs": [],
      "source": [
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3jeEFJTOKRk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I4uuWdW8OMS_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_sparse\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.utils import negative_sampling, to_networkx\n",
        "from typing import Union, Tuple\n",
        "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "import torch_geometric.nn.conv as ccgeo\n",
        "from torch_geometric.nn.conv import MessagePassing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUEHxr8ZN2XC",
        "outputId": "bcde3a87-806f-49eb-da29-ef4ac9d57063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear, ReLU\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.utils import negative_sampling, to_networkx\n",
        "from typing import Union, Tuple\n",
        "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "import torch_geometric.nn.conv as ccgeo\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "import pynvml as pynv\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_sparse\n",
        "\n",
        "import math\n",
        "##### SCRIPT STARTS HERE #####\n",
        "#!usr/bin/bash python\n",
        "filename=\"test.txt\"\n",
        "\n",
        "\n",
        "def get_spd_matrix_original(G, S, max_spd=5):\n",
        "  print(len(G))\n",
        "  spd_matrix = np.zeros((G.number_of_nodes(), len(S)), dtype=np.float32) # returns a 0-matrix of (4267, 500)\n",
        "  for i, node_S in enumerate(S):                                          # i is index of for loop, node_S is the i-th element of S (current node)\n",
        "      for node, length in nx.shortest_path_length(G, source=node_S).items():  # iterate over the Graph where source is node_S, let length denote the distance from node_S to current node\n",
        "          spd_matrix[node, i] = min(length, max_spd)                          # refill element spd[node,i] with min(length, max_spd)  \n",
        "  return spd_matrix\n",
        "\n",
        "def get_spd_matrix_average_distance(G, S): # nx_graph is the complete graph networkx DS, node_subset is np.random.choice(nx_graph.number_of_nodes(), size=500, replace=False)\n",
        "    # \"\"\"S parameter draws (In the original version, get_spd_matrix is called in line ~363ish) 500 random samples within range 0 to G.number_of_nodes(),\n",
        "    # (in one instance, this range is 0 to 4267)\n",
        "    # \"\"\"\n",
        "    average = nx.average_shortest_path_length(G)\n",
        "    spd_matrix = np.zeros((G.number_of_nodes(), len(S)), dtype=np.float32) # returns a 0-matrix of (4267, 500)\n",
        "    for i, node_S in enumerate(S):                                          # i is index of for loop, node_S is the i-th element of S (current node)\n",
        "        for node, length in nx.shortest_path_length(G, source=node_S).items():  # iterate over the Graph where source is node_S, let length denote the distance from node_S to current node\n",
        "            spd_matrix[node, i] = length / average                 # refill element spd[node,i] with min(length, max_spd)  \n",
        "    return spd_matrix\n",
        "\n",
        "def get_similarity_spd_matrix(G, S, max_spd=5): # nx_graph is the complete graph networkx DS, node_subset is np.random.choice(nx_graph.number_of_nodes(), size=500, replace=False)\n",
        "    # \"\"\"S parameter draws (In the original version, get_spd_matrix is called in line ~363ish) 500 random samples within range 0 to G.number_of_nodes(),\n",
        "    # (again , in one instance, this range is 0 to 4267)\n",
        "    # \"\"\"\n",
        "    print(len(G))\n",
        "    spd_matrix = np.zeros((G.number_of_nodes(), len(S)), dtype=np.float32) # returns a 0-matrix of (4267, 500)\n",
        "    print(\"spd_for\")\n",
        "    for i, node_S in enumerate(S):                                          # i is index of for loop, node_S is the i-th element of S (current node)\n",
        "        for node, length in nx.shortest_path_length(G, source=node_S).items():  # iterate over the Graph where source is node_S, let length denote the distance from node_S to current node\n",
        "            spd_matrix[node, i] = min(length, max_spd)                          # refill element spd[node,i] with min(length, max_spd)  \n",
        "            # print(\"spd_matrix[node, i]: \", spd_matrix[node, i])   \n",
        "                                      \n",
        "        for node, similarity in nx.simrank_similarity(G, source=node_S).items():  \n",
        "            spd_matrix[node, i] = spd_matrix[node, i] + 150*similarity  \n",
        "            # print(\"After similarity addition, spd_matrix[node, i]: \", spd_matrix[node, i])   \n",
        "            # print(\"Similarity: \", 100*similarity)       \n",
        "    \n",
        "    print(\"spd_end\")\n",
        "    return spd_matrix\n",
        "\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    def __init__(self, runs, info=None):\n",
        "        self.info = info\n",
        "        self.results = [[] for _ in range(runs)]\n",
        "\n",
        "    def add_result(self, run, result):\n",
        "        assert len(result) == 2\n",
        "        assert run >= 0 and run < len(self.results)\n",
        "        self.results[run].append(result)\n",
        "\n",
        "    def print_statistics(self, run=None):\n",
        "        global filename\n",
        "        f = open(filename, \"a\")\n",
        "        if run is not None:\n",
        "            result = 100 * torch.tensor(self.results[run])\n",
        "            x_df = pd.DataFrame(result)\n",
        "            x_df.to_csv('tmp.csv')\n",
        "            argmax = result[:, 0].argmax().item()\n",
        "            print(f'Run {run + 1:02d}:', file=f)\n",
        "            print(f'Highest Valid: {result[:, 0].max():.2f}', file=f)\n",
        "            print(f'Highest Test: {result[:, 1].max():.2f}', file=f)\n",
        "            print(f'   Final Test: {result[argmax, 1]:.2f}', file=f)\n",
        "        else:\n",
        "            result = 100 * torch.tensor(self.results)\n",
        "            best_results = []\n",
        "            for r in result:\n",
        "                valid = r[:, 0].max().item()\n",
        "                test = r[r[:, 0].argmax(), 1].item()\n",
        "                best_results.append((valid, test))\n",
        "            best_result = torch.tensor(best_results)\n",
        "            print(f'All runs:', file=f)\n",
        "            r = best_result[:, 0]\n",
        "            print(f'Highest Valid: {r.mean():.4f} ± {r.std():.4f}', file=f)\n",
        "            r = best_result[:, 1]\n",
        "            print(f'   Final Test: {r.mean():.4f} ± {r.std():.4f}', file=f)\n",
        "        f.close()\n",
        "\n",
        "class SAGEConv(MessagePassing):\n",
        "    r\"\"\"The GraphSAGE operator from the `\"Inductive Representation Learning on\n",
        "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper\n",
        "\n",
        "    .. math::\n",
        "        \\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W}_2 \\cdot\n",
        "        \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j\n",
        "\n",
        "    Args:\n",
        "        in_channels (int or tuple): Size of each input sample. A tuple\n",
        "            corresponds to the sizes of source and target dimensionalities.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        normalize (bool, optional): If set to :obj:`True`, output features\n",
        "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
        "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
        "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
        "            (default: :obj:`False`)\n",
        "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
        "            not add transformed root node features to the output.\n",
        "            (default: :obj:`True`)\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
        "                 out_channels: int, normalize: bool = False,\n",
        "                 root_weight: bool = True,\n",
        "                 bias: bool = True, **kwargs):  # yapf: disable\n",
        "        kwargs.setdefault('aggr', 'mean')\n",
        "        super(SAGEConv, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "        self.root_weight = root_weight\n",
        "        self.relu = ReLU(inplace=True)\n",
        "\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        self.lin_l = Linear(in_channels[0], out_channels, bias=bias)\n",
        "        if self.root_weight:\n",
        "            self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        if self.root_weight:\n",
        "            self.lin_r.reset_parameters()\n",
        "\n",
        "\n",
        "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, size: Size = None) -> Tensor:\n",
        "        \"\"\"\"\"\"\n",
        "        if isinstance(x, Tensor):\n",
        "            x: OptPairTensor = (x, x)\n",
        "\n",
        "        # Node and edge feature dimensionalites need to match.\n",
        "        if isinstance(edge_index, Tensor):\n",
        "            assert edge_attr is not None\n",
        "            assert x[0].size(-1) == edge_attr.size(-1)\n",
        "        elif isinstance(edge_index, SparseTensor):\n",
        "            assert x[0].size(-1) == edge_index.size(-1)\n",
        "\n",
        "        # propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\n",
        "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, size=size)\n",
        "        out = self.lin_l(out)\n",
        "\n",
        "        x_r = x[1]\n",
        "        if self.root_weight and x_r is not None:\n",
        "            out += self.lin_r(x_r)\n",
        "\n",
        "        if self.normalize:\n",
        "            out = F.normalize(out, p=2., dim=-1)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
        "        # all=x_j + edge_attr\n",
        "        # all=all.cpu()\n",
        "        # # all_list=list(torch.split(all, 1000000, dim=0)).cpu()\n",
        "        # # print(len(all_list))\n",
        "\n",
        "        # device = 'cuda:0'\n",
        "        # device = torch.device(device)\n",
        "        # return F.relu(all).to(device)\n",
        "        return F.relu(x_j + edge_attr)\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
        "                                   self.out_channels)\n",
        "\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
        "        super(GraphSAGE,self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t, edge_attr, emb_ea):\n",
        "        edge_attr = torch.mm(edge_attr, emb_ea)\n",
        "        for conv in self.convs[:-1]:\n",
        "            torch.cuda.empty_cache()\n",
        "            x = conv(x, adj_t, edge_attr)\n",
        "            torch.cuda.empty_cache()\n",
        "            x = F.relu(x,inplace=True)\n",
        "            torch.cuda.empty_cache()\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "            torch.cuda.empty_cache()\n",
        "        x = self.convs[-1](x, adj_t, edge_attr)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout):\n",
        "        super(LinkPredictor, self).__init__()\n",
        "\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
        "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for lin in self.lins:\n",
        "            lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        x = x_i * x_j\n",
        "        for lin in self.lins[:-1]:\n",
        "            x = lin(x)\n",
        "            x = F.relu(x,inplace=True)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.lins[-1](x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "def train(model, predictor, edge_attr, x, emb_ea, adj_t, split_edge, optimizer,device, batch_size):\n",
        "    edge_index = adj_t\n",
        "    model.train()\n",
        "    predictor.train()\n",
        "    pos_train_edge = split_edge\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size, shuffle=True,num_workers =4):\n",
        "        # torch.cuda.empty_cache()\n",
        "        optimizer.zero_grad()\n",
        "        # h will be embeddings\n",
        "        # x are the embeddings before\n",
        "        # adj_t is edge index (All REAL edges)\n",
        "        # edge_attr is x3 sampling of SPD\n",
        "        # emb_ea is embedding of edges\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        h = model(x, adj_t, edge_attr, emb_ea)\n",
        "        # torch.cuda.empty_cache()\n",
        "        # print(\"Model output shape:\",h.shape)\n",
        "        # edge: we get a sampling of positive edge connections between nodes by using perm(list of nodes for the batch we know are positive)\n",
        "        edge = pos_train_edge[perm].t()\n",
        "        # we pass the edge list inside embedding h\n",
        "        # we devide in edge[0] and edge[1] to devide the connected from->to\n",
        "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
        "        # neg_sampling(we get negative edges from dataset) REAL ONES! they use the full dataset!!! VERY GOOD :)\n",
        "        edge = negative_sampling(edge_index, num_nodes=x.size(0),\n",
        "                                 num_neg_samples=perm.size(0), method='dense')\n",
        "\n",
        "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
        "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
        "\n",
        "        loss = pos_loss + neg_loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(x, 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        num_examples = pos_out.size(0)\n",
        "        total_loss += loss.item() * num_examples\n",
        "        total_examples += num_examples\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, predictor, edge_attr, x, emb_ea, adj_t, split_edge, evaluator, batch_size):\n",
        "    model.eval()\n",
        "    predictor.eval()\n",
        "\n",
        "    h = model(x, adj_t, edge_attr, emb_ea)\n",
        "\n",
        "    pos_valid_edge = split_edge['valid']['edge'].to(x.device)\n",
        "    neg_valid_edge = split_edge['valid']['edge_neg'].to(x.device)\n",
        "    pos_test_edge = split_edge['test']['edge'].to(x.device)\n",
        "    neg_test_edge = split_edge['test']['edge_neg'].to(x.device)\n",
        "\n",
        "    pos_valid_preds = []\n",
        "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
        "        edge = pos_valid_edge[perm].t()\n",
        "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
        "\n",
        "    neg_valid_preds = []\n",
        "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
        "        edge = neg_valid_edge[perm].t()\n",
        "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
        "\n",
        "    pos_test_preds = []\n",
        "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
        "        edge = pos_test_edge[perm].t()\n",
        "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
        "\n",
        "    neg_test_preds = []\n",
        "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
        "        edge = neg_test_edge[perm].t()\n",
        "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
        "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
        "\n",
        "    results = {}\n",
        "    for K in [20, 50, 100]:\n",
        "        evaluator.K = K\n",
        "        valid_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_valid_pred,\n",
        "            'y_pred_neg': neg_valid_pred,\n",
        "        })[f'hits@{K}']\n",
        "        test_hits = evaluator.eval({\n",
        "            'y_pred_pos': pos_test_pred,\n",
        "            'y_pred_neg': neg_test_pred,\n",
        "        })[f'hits@{K}']\n",
        "\n",
        "        results[f'Hits@{K}'] = (valid_hits, test_hits)\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_gpu_utilization(position):\n",
        "    print(position)\n",
        "    os.system(\"nvidia-smi\")\n",
        "    # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "\n",
        "\n",
        "def main():\n",
        "    cuda_device = '0'\n",
        "    print('Done')\n",
        "    global filename\n",
        "    parser = argparse.ArgumentParser(description='Link_Pred_DDI')\n",
        "    parser.add_argument('--device', type=str, default=\"cuda:0\")\n",
        "    parser.add_argument('--num_layers', type=int, default=2)\n",
        "    parser.add_argument('--num_samples', type=int, default=5)\n",
        "    parser.add_argument('--node_emb', type=int, default=256)\n",
        "    parser.add_argument('--hidden_channels', type=int, default=256)\n",
        "    parser.add_argument('--dropout', type=float, default=0.3)\n",
        "    parser.add_argument('--spd_size', type=int, default=500)\n",
        "    # parser.add_argument('--batch_size', type=int, default=1) \n",
        "    # TODO\n",
        "    parser.add_argument('--batch_size', type=int, default=64 * 1024)\n",
        "    parser.add_argument('--lr', type=float, default=0.003)\n",
        "    parser.add_argument('--epochs', type=int, default=400)\n",
        "    parser.add_argument('--log_steps', type=int, default=1)\n",
        "    parser.add_argument('--eval_steps', type=int, default=1)\n",
        "    parser.add_argument('--runs', type=int, default=10)\n",
        "\n",
        "    parser.add_argument('--type', type=str, default=\"original\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "    device = args.device if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "    \n",
        "\n",
        "    dataset = PygLinkPropPredDataset(name='ogbl-ddi')\n",
        "    data = dataset[0]\n",
        "    print(data.size())\n",
        "    edge_index = data.edge_index.to(device)\n",
        "    print_gpu_utilization(\"Start\")\n",
        "\n",
        "    split_edge = dataset.get_edge_split()\n",
        "\n",
        "    model = GraphSAGE(args.node_emb, args.hidden_channels, args.hidden_channels,\n",
        "                      args.num_layers, args.dropout).to(device)\n",
        "\n",
        "    emb = torch.nn.Embedding(data.num_nodes, args.node_emb).to(device)\n",
        "    emb_ea = torch.nn.Embedding(args.num_samples, args.node_emb).to(device)\n",
        "    predictor = LinkPredictor(args.hidden_channels, args.hidden_channels, 1,\n",
        "                              args.num_layers+1, args.dropout).to(device)\n",
        "\n",
        "    print('Number of parameters:',\n",
        "          sum(p.numel() for p in list(model.parameters()) +\n",
        "          list(predictor.parameters()) + list(emb.parameters()) + list(emb_ea.parameters())))\n",
        "\n",
        "    # encode distance information\n",
        "    np.random.seed(0)\n",
        "    nx_graph = to_networkx(data, to_undirected=True)\n",
        "    node_mask = []\n",
        "    spd_size=args.spd_size\n",
        "    for _ in range(args.num_samples):\n",
        "        node_mask.append(np.random.choice(spd_size, size=int(np.round(spd_size/2.5)), replace=False))\n",
        "    node_mask = np.array(node_mask)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    type_exec=args.type\n",
        "\n",
        "    original_subset = np.random.choice(nx_graph.number_of_nodes(), size=spd_size, replace=False)\n",
        "    if(type_exec==\"original\"):\n",
        "      print(\"Original method selected\")\n",
        "      filename=\"./gdrive/MyDrive/output_original.txt\"\n",
        "      spd = get_spd_matrix_original(G=nx_graph, S=original_subset, max_spd=5)\n",
        "    elif(type_exec==\"average\"):\n",
        "      print(\"Average method selected\")\n",
        "      filename=\"./gdrive/MyDrive/output_average.txt\"\n",
        "      spd = get_spd_matrix_average_distance(G=nx_graph, S=original_subset)\n",
        "    elif(type_exec==\"top-k\"):\n",
        "      print(\"top-k method selected\")\n",
        "      filename=\"./gdrive/MyDrive/output_topk.txt\"\n",
        "      S = sorted(nx_graph.degree, key=lambda x: x[1], reverse=True)\n",
        "      S = S[0:spd_size]\n",
        "      s_nodes = np.zeros(len(S))\n",
        "      for i in range(len(S)):\n",
        "          s_nodes[i] = S[i][0] \n",
        "      s_nodes = s_nodes.astype(int)\n",
        "      spd = get_spd_matrix_original(G=nx_graph, S=s_nodes, max_spd=5)\n",
        "    elif(type_exec==\"similarity\"):\n",
        "      print(\"Similarity method selected\")\n",
        "      filename=\"./gdrive/MyDrive/output_similarity.txt\"\n",
        "      spd = get_similarity_spd_matrix(G=nx_graph, S=original_subset, max_spd=5)\n",
        "    else:\n",
        "      print(\"Original method auto-chosen\")\n",
        "      filename=\"./gdrive/MyDrive/output_original.txt\"\n",
        "      spd = get_spd_matrix_original(G=nx_graph, S=original_subset, max_spd=5)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    spd = torch.Tensor(spd).to(device)\n",
        "    print_gpu_utilization(\"spd loaded\")\n",
        "    edge_attr = spd[edge_index, :].mean(0)[:, node_mask].mean(2)\n",
        "    a_max = torch.max(edge_attr, dim=0, keepdim=True)[0]\n",
        "    a_min = torch.min(edge_attr, dim=0, keepdim=True)[0]\n",
        "    edge_attr = (edge_attr - a_min) / (a_max - a_min + 1e-6)\n",
        "    evaluator = Evaluator(name='ogbl-ddi')\n",
        "    loggers = {\n",
        "        'Hits@20': Logger(args.runs, args),\n",
        "        'Hits@50': Logger(args.runs, args),\n",
        "        'Hits@100': Logger(args.runs, args),\n",
        "    }\n",
        "    for run in range(args.runs):\n",
        "        torch.cuda.empty_cache()\n",
        "        # print_gpu_utilization(\"start run cache cleared\")\n",
        "        random.seed(run)\n",
        "        torch.manual_seed(run)\n",
        "        torch.nn.init.xavier_uniform_(emb.weight)\n",
        "        torch.nn.init.xavier_uniform_(emb_ea.weight)\n",
        "        model.reset_parameters()\n",
        "        predictor.reset_parameters()\n",
        "        optimizer = torch.optim.Adam(\n",
        "            list(model.parameters()) + list(emb.parameters()) +\n",
        "            list(emb_ea.parameters()) + list(predictor.parameters()), lr=args.lr)\n",
        "        split_edge_in=split_edge['train']['edge'].to(device)\n",
        "        for epoch in range(1, 1 + args.epochs):\n",
        "            torch.cuda.empty_cache()\n",
        "            # print_gpu_utilization(\"in epoch cache cleared\")\n",
        "            loss = train(model, predictor, edge_attr, emb.weight, emb_ea.weight, edge_index, split_edge_in,\n",
        "                         optimizer,device, args.batch_size)\n",
        "            torch.cuda.empty_cache()\n",
        "            # print_gpu_utilization(\"after pass cache cleared\")\n",
        "            if epoch % args.eval_steps == 0:\n",
        "                results = test(model, predictor, edge_attr, emb.weight, emb_ea.weight, edge_index, split_edge,\n",
        "                               evaluator, args.batch_size)\n",
        "                for key, result in results.items():\n",
        "                    loggers[key].add_result(run, result)\n",
        "\n",
        "                if epoch % args.log_steps == 0:\n",
        "                    f = open(filename, \"a\")\n",
        "                    for key, result in results.items():\n",
        "                        valid_hits, test_hits = result\n",
        "                        print(key, file=f)\n",
        "                        print(f'Run: {run + 1:02d}, '\n",
        "                              f'Epoch: {epoch:02d}, '\n",
        "                              f'Loss: {loss:.4f}, '\n",
        "                              f'Valid: {100 * valid_hits:.2f}%, '\n",
        "                              f'Test: {100 * test_hits:.2f}%', file=f)\n",
        "                    print('---', file=f)\n",
        "                    f.close()\n",
        "        torch.save(model,\"save.pth\")\n",
        "        for key in loggers.keys():\n",
        "            print(key)\n",
        "            loggers[key].print_statistics(run)\n",
        "\n",
        "    for key in loggers.keys():\n",
        "        print(key)\n",
        "        loggers[key].print_statistics()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original\n",
        "average\n",
        "top-k\n",
        "similarity"
      ],
      "metadata": {
        "id": "Bur69eLF9qbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJmzOrHQPKld"
      },
      "outputs": [],
      "source": [
        "# Run Training (Original code)\n",
        "!python3 main.py --node_emb 254 --hidden_channels 254 --num_samples 3 --num_layers 2 --epochs 1000 --spd_size 500 --runs 1 --type original"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training (Average code)\n",
        "!python3 main.py --node_emb 254 --hidden_channels 254 --num_samples 3 --num_layers 2 --epochs 1000 --spd_size 500 --runs 1 --type average"
      ],
      "metadata": {
        "id": "SaUMpTGdIUb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training (Top-k code)\n",
        "!python3 main.py --node_emb 254 --hidden_channels 254 --num_samples 3 --num_layers 2 --epochs 1000 --spd_size 500 --runs 1 --type top-k"
      ],
      "metadata": {
        "id": "Sey4yxMLIYbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training (similarity code)\n",
        "!python3 main.py --node_emb 254 --hidden_channels 254 --num_samples 3 --num_layers 2 --epochs 1000 --spd_size 500 --runs 1 --type similarity"
      ],
      "metadata": {
        "id": "LadukQ_AIbPh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "gdl_split.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}